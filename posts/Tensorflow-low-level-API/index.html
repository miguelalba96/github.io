<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.2.1" /><meta property="og:title" content="How to build deep neural networks using Tensorflow low level API (tf.Module)" /><meta name="author" content="Miguel Alba" /><meta property="og:locale" content="en" /><meta name="description" content="Introduction" /><meta property="og:description" content="Introduction" /><link rel="canonical" href="https://miguelalba96.github.io/posts/Tensorflow-low-level-API/" /><meta property="og:url" content="https://miguelalba96.github.io/posts/Tensorflow-low-level-API/" /><meta property="og:site_name" content="Miguel Alba" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-11-28T21:00:00+01:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="How to build deep neural networks using Tensorflow low level API (tf.Module)" /><meta name="twitter:site" content="@twitter_username" /><meta name="twitter:creator" content="@Miguel Alba" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"author":{"@type":"Person","name":"Miguel Alba"},"description":"Introduction","url":"https://miguelalba96.github.io/posts/Tensorflow-low-level-API/","@type":"BlogPosting","headline":"How to build deep neural networks using Tensorflow low level API (tf.Module)","dateModified":"2022-12-30T13:56:02+01:00","datePublished":"2021-11-28T21:00:00+01:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://miguelalba96.github.io/posts/Tensorflow-low-level-API/"},"@context":"https://schema.org"}</script><title>How to build deep neural networks using Tensorflow low level API (tf.Module) | Miguel Alba</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Miguel Alba"><meta name="application-name" content="Miguel Alba"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/me.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Miguel Alba</a></div><div class="site-subtitle font-italic">Posts on ML, Stats and general purpose data science</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a><li class="nav-item"> <a href="/research/" class="nav-link"> <i class="fa-fw fas fa-flask ml-xl-3 mr-xl-3 unloaded"></i> <span>RESEARCH</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <a href="https://github.com/miguelalba96" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://www.instagram.com/malba96" aria-label="instagram" class="order-4" target="_blank" rel="noopener"> <i class="fab fa-instagram"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['albaacosta','uni-potsdam.de'].join('@')" aria-label="email" class="order-5" > <i class="fas fa-envelope"></i> </a> <a href="https://www.linkedin.com/in/miguelalba96" aria-label="linkedin" class="order-6" > <i class="fab fa-linkedin"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>How to build deep neural networks using Tensorflow low level API (tf.Module)</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>How to build deep neural networks using Tensorflow low level API (tf.Module)</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> Miguel Alba </span> on <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Sun, Nov 28, 2021, 9:00 PM +0100" >Nov 28, 2021<i class="unloaded">2021-11-28T21:00:00+01:00</i> </span></div><div> <span> Updated <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Fri, Dec 30, 2022, 1:56 PM +0100" >Dec 30<i class="unloaded">2022-12-30T13:56:02+01:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1588 words">8 min read</span></div></div><div class="post-content"> <img data-proofer-ignore data-src="/assets/img/python_header_image.jpg" class="preview-img" alt="Preview Image" ><h2 id="introduction">Introduction</h2><p>Just before the release of Tensorflow 2.0 (mid 2019), developing large and complex deep learning models with Tensorflow 1.x required some understanding of how <strong>static graph</strong> semantics worked using <code class="language-plaintext highlighter-rouge">tf.Session</code>. This usually made machine learning development processes extremely complicated, difficult to explain and understand. Because of this the enthusiasm of new deep learning practitioners excited to learn TF, was reduced to migrating to more friendly or pythonic options such as Keras or PyTorch.</p><p>Since Tensorflow 2.0 there are two types of APIs used to build and train deep neural networks. The first and most known is <code class="language-plaintext highlighter-rouge">tf.keras</code> which contains a high amount of tutorials and documentation available across the internet (the most known is the official tensorflow <a href="https://www.tensorflow.org/api_docs/python/tf/keras">documentation</a>), but what if we don’t want to rely on <code class="language-plaintext highlighter-rouge">tf.keras</code> development to build and train deep neural networks, but make our own layers, operations and models with native Tensorflow code?</p><p>This post explains in detail how to define, build and call layers and models using Tensorflow’s low level API.</p><h2 id="base-neural-networks-class-tfmodule">Base Neural Networks Class (tf.Module)</h2><p>As the official <a href="https://www.tensorflow.org/api_docs/python/tf/Module">tensorflow documentation</a> says, <code class="language-plaintext highlighter-rouge">tf.Module</code> is a base class for deep neural networks, quite similar to what we have in PyTorch using <code class="language-plaintext highlighter-rouge">nn.Module</code>. If we want to build a new layer/operation or model, we have to subclass <code class="language-plaintext highlighter-rouge">tf.Module</code> and initialize all trainable/non-trainable parameters using <a href="https://www.tensorflow.org/api_docs/python/tf/Variable"><code class="language-plaintext highlighter-rouge">tf.Variable</code></a>.</p><p>For this example and as a complement to the recent update of the official documentation (which explains clearly how to build a <strong>Multilayer Perceptron Network - MLP</strong>). We will create a <strong>Convolutional Neural Network CNN</strong>.</p><h3 id="create-a-new-trainable-layer">Create a new trainable layer</h3><ol><li><p>To start, we need to define our trainable variables (a.k.a weights), to do this we need to initialize them using some initialization method (ex. Normal, Glorot, Xavier, etc). In the case of deep neural networks we are interested in defining and training <em>weights</em> and <em>biases</em></p><div class="language-python highlighter-rouge"><div class="code-header"> <span text-data=" Python "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre> <span class="k">def</span> <span class="nf">weights</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.02</span><span class="p">):</span>
     <span class="c1"># for this case I am using a normal distribution
</span>     <span class="n">var</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">random_normal_initializer</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="n">stddev</span><span class="p">)(</span><span class="n">shape</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
     <span class="k">return</span> <span class="n">var</span>


 <span class="k">def</span> <span class="nf">bias</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">constant</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
     <span class="n">var</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">constant_initializer</span><span class="p">(</span><span class="n">constant</span><span class="p">)(</span><span class="n">shape</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
     <span class="k">return</span> <span class="n">var</span>
</pre></table></code></div></div><li><p>We want to create an object for our new layer, in this case a 2D convolutional layer, in contrast to the official TF docs, we can create the shapes of the <em>weights</em> and <em>biases</em> inferring their shapes directly on the first forward pass</p><div class="language-python highlighter-rouge"><div class="code-header"> <span text-data=" Python "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
</pre><td class="rouge-code"><pre> <span class="k">class</span> <span class="nc">Conv2D</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
     <span class="s">"""
     Custom Convolutional layer with explicit padding
     """</span>
     <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_filters</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                 <span class="n">act_type</span><span class="o">=</span><span class="s">'ReLU'</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
         <span class="s">"""
         :param: num_filters: Number of filters
         :param: kernel_size: kernel size
         :param: padding: explicit padding (0 to not use padding int=&gt;1 to pad input)
         :param: strides: explicit strides
         :param: act_type: activation type
         :param: name: name of the layer
         """</span>
         <span class="nb">super</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
         <span class="bp">self</span><span class="p">.</span><span class="n">filters</span> <span class="o">=</span> <span class="n">num_filters</span>
         <span class="bp">self</span><span class="p">.</span><span class="n">ks</span> <span class="o">=</span> <span class="n">kernel_size</span>
         <span class="bp">self</span><span class="p">.</span><span class="n">pad</span> <span class="o">=</span> <span class="p">[[</span><span class="n">padding</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span>
         <span class="bp">self</span><span class="p">.</span><span class="n">s</span> <span class="o">=</span> <span class="n">strides</span>
         <span class="bp">self</span><span class="p">.</span><span class="n">act_type</span> <span class="o">=</span> <span class="n">act_type</span>

     <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
         <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s">'weights'</span><span class="p">):</span>
             <span class="bp">self</span><span class="p">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="p">(</span><span class="s">'weights'</span><span class="p">,</span> 
                                 <span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">ks</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">ks</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="p">.</span><span class="n">filters</span><span class="p">))</span>
         <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s">'bias'</span><span class="p">):</span>
             <span class="bp">self</span><span class="p">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">bias</span><span class="p">(</span><span class="s">'bias'</span><span class="p">,</span> <span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">filters</span><span class="p">))</span>

     <span class="o">@</span><span class="n">tf</span><span class="p">.</span><span class="n">Module</span><span class="p">.</span><span class="n">with_name_scope</span> <span class="c1"># keep track of the variables names and their hierarchies
</span>     <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
         <span class="c1"># build weights and biases
</span>         <span class="n">input_shape</span> <span class="o">=</span> <span class="nb">input</span><span class="p">.</span><span class="n">get_shape</span><span class="p">()</span>
         <span class="bp">self</span><span class="p">.</span><span class="n">build</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>

         <span class="c1"># explicit zero padding and convolution
</span>         <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">pad</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">pad</span> <span class="o">+</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> <span class="n">constant_values</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
         <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">s</span><span class="p">]</span><span class="o">*</span><span class="mi">4</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'VALID'</span><span class="p">)</span>
         <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">bias_add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">bias</span><span class="p">)</span>

         <span class="c1"># activation (in this case only ReLU)
</span>         <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">act_type</span> <span class="o">==</span> <span class="s">'ReLU'</span> <span class="k">else</span> <span class="n">x</span>
         <span class="k">return</span> <span class="n">x</span>
</pre></table></code></div></div><li><p>We can test if the layer implementation is working correctly by calling it and getting its variables (the weight’s tensors):</p><div class="language-python highlighter-rouge"><div class="code-header"> <span text-data=" Python "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre> <span class="c1"># create fake image
</span> <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

 <span class="n">conv</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="n">num_filters</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">'test_conv'</span><span class="p">)</span>
 <span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># forward pass on the layer
</span>
 <span class="c1"># then we can print the weights created to verify their values and shapes
</span> <span class="n">conv</span><span class="p">.</span><span class="n">trainable_variables</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span text-data=" Text "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
</pre><td class="rouge-code"><pre>
 (&lt;tf.Variable 'test_conv/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)&gt;,
 &lt;tf.Variable 'test_conv/weights:0' shape=(3, 3, 3, 4) dtype=float32, numpy=
 array([[[[ 0.00553657,  0.01345694,  0.0160969 , -0.00974667],
         [-0.0174912 , -0.00867653,  0.01673212, -0.01981817],
         [ 0.00546766, -0.00352232,  0.01730617,  0.03613425]],
    
         [[-0.02024776,  0.00949733, -0.01584678, -0.0232379 ],
         [-0.00929332,  0.00113463, -0.00618072, -0.00331176],
         [ 0.01551097, -0.01571138,  0.01730444, -0.00512385]],
    
         [[-0.00026536,  0.02602397,  0.03468624, -0.01000871],
         [-0.00465783, -0.01016334,  0.01106991, -0.02338664],
         [-0.00632419, -0.02121128,  0.02255995, -0.00294858]]],
    
    
         [[[ 0.01078237, -0.01998009, -0.01237592, -0.01769269],
         [ 0.01115903, -0.02444682, -0.02847697, -0.00149765],
         [ 0.01714881,  0.03219299,  0.00256057, -0.01943027]],
    
         [[ 0.03568217, -0.00663988,  0.01306447, -0.02267795],
         [ 0.00643562, -0.02551239, -0.02827096, -0.02343682],
         [-0.00941015, -0.00949762,  0.04840184,  0.00754907]],
    
         [[-0.00122065, -0.0315739 , -0.01874557,  0.00350243],
         [-0.02523333,  0.0312549 , -0.00660984,  0.0077161 ],
         [ 0.01008623, -0.00679884, -0.02994534,  0.00870273]]],
    
    
         [[[ 0.00458873,  0.02161162, -0.00432352,  0.00619686],
         [ 0.00921444, -0.00113679, -0.01196389, -0.0254667 ],
         [ 0.0068634 , -0.00199798,  0.04269401,  0.05141414]],
    
         [[-0.01473054, -0.02008617, -0.02860904,  0.03205349],
         [ 0.01996609, -0.00063833, -0.00017963,  0.00412473],
         [ 0.02097527,  0.03115197,  0.00866693,  0.01411885]],
    
         [[ 0.02391446, -0.01629277,  0.02057827,  0.00664399],
         [ 0.00774666, -0.01262378, -0.0365187 , -0.01844351],
         [-0.00975288, -0.01222847,  0.00185206,  0.01441888]]]],
     dtype=float32)&gt;)

</pre></table></code></div></div><p>Have a look on how the name of the weights maintain an order of <strong>“name_of_layer/name_of_weight”</strong>.</p><p>We can also check the size of the output tensor:</p><div class="language-python highlighter-rouge"><div class="code-header"> <span text-data=" Python "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre> <span class="c1"># shapes of the output 
</span> <span class="n">y</span><span class="p">.</span><span class="n">get_shape</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span text-data=" Text "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre> TensorShape([1, 128, 128, 4])
</pre></table></code></div></div></ol><h3 id="create-a-model">Create a model</h3><p>Once the layers are defined with <code class="language-plaintext highlighter-rouge">tf.Module</code> we can write a complete model. In this case a CNN. To do this, we first have to define a couple of common operations used in these type of models, e.g. max-pooling, linear/dense layers, etc.</p><p>Starting with max pool (quite similar to what can be expected in tensorflow 1.x but without the name scoping):</p><div class="language-python highlighter-rouge"><div class="code-header"> <span text-data=" Python "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'VALID'</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="s">"""
    Common max-pooling 2D layer
    """</span>
    <span class="c1"># Here we are not explicitly padding the input as in the Conv2D
</span>    <span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span> <span class="ow">or</span> <span class="n">size</span> <span class="c1"># if no stride is given use the pool size
</span>    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span>
                         <span class="n">ksize</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                         <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                         <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span> 
                         <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>
</pre></table></code></div></div><p>Next, we can refine the <code class="language-plaintext highlighter-rouge">Dense</code> layer of the TF <a href="https://www.tensorflow.org/api_docs/python/tf/Module">documentation</a> a bit with the tweaks of the <code class="language-plaintext highlighter-rouge">Conv2D</code> layer defined above as follows:</p><div class="language-python highlighter-rouge"><div class="code-header"> <span text-data=" Python "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
</pre><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">Dense</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">,</span> <span class="n">act_type</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Dense</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">num_outs</span> <span class="o">=</span> <span class="n">num_outputs</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">act_type</span> <span class="o">=</span> <span class="n">act_type</span>
  
    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s">'weights'</span><span class="p">):</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="p">(</span><span class="s">'weights'</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">input_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="p">.</span><span class="n">num_outs</span><span class="p">))</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s">'bias'</span><span class="p">):</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">bias</span><span class="p">(</span><span class="s">'bias'</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">num_outs</span><span class="p">))</span>

    <span class="o">@</span><span class="n">tf</span><span class="p">.</span><span class="n">Module</span><span class="p">.</span><span class="n">with_name_scope</span>
    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="c1"># build weights first call
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">build</span><span class="p">(</span><span class="n">inputs</span><span class="p">.</span><span class="n">get_shape</span><span class="p">())</span>

        <span class="c1"># linear operation 
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">weights</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">bias</span>

        <span class="c1"># activations 
</span>        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">act_type</span> <span class="o">==</span> <span class="s">'ReLU'</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="p">.</span><span class="n">act_type</span> <span class="o">==</span> <span class="s">'Sigmoid'</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">x</span>
</pre></table></code></div></div><p>Then we write the final model (using again <code class="language-plaintext highlighter-rouge">tf.Module</code>):</p><div class="language-python highlighter-rouge"><div class="code-header"> <span text-data=" Python "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
</pre><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">CNN</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
        <span class="k">with</span> <span class="bp">self</span><span class="p">.</span><span class="n">name_scope</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">'C64'</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s">'C64'</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s">'C64'</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">conv4</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s">'C64'</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">'output'</span><span class="p">,</span> <span class="n">act_type</span><span class="o">=</span><span class="s">'Sigmoid'</span><span class="p">)</span> 

    <span class="o">@</span><span class="n">tf</span><span class="p">.</span><span class="n">Module</span><span class="p">.</span><span class="n">with_name_scope</span>
    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">conv1</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">conv4</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># flatten op
</span>        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">out</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>
</pre></table></code></div></div><p>In this case the model has 4 conv layers for downsampling and 1 final fully connected layer associated to binary output (note the sigmoid activation).</p><p>We can test this model by simply passing an image and checking the model’s output:</p><div class="language-python highlighter-rouge"><div class="code-header"> <span text-data=" Python "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="c1"># Test the CNN
</span><span class="n">fake_image</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span> 
<span class="n">net</span> <span class="o">=</span> <span class="n">CNN</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">'simple_model'</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span> <span class="c1"># probability
</span></pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span text-data=" Text "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>tf.Tensor([[0.50065225]], shape=(1, 1), dtype=float32)
</pre></table></code></div></div><p>In order to check the correctness of the name scoping we can always print how some variables may look like when debugging. For example, here I want to check if my last layer follows the appropriate hierarchy <code class="language-plaintext highlighter-rouge">(model_name/name_of_the_layer/name_of_the_weight)</code>:</p><div class="language-python highlighter-rouge"><div class="code-header"> <span text-data=" Python "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">output_variables</span> <span class="o">=</span> <span class="p">[</span><span class="n">var</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">net</span><span class="p">.</span><span class="n">trainable_variables</span> <span class="k">if</span> <span class="s">'output'</span> <span class="ow">in</span> <span class="n">var</span><span class="p">.</span><span class="n">name</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="n">output_variables</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span text-data=" Text "><i class="fa-fw fas fa-code small"></i></span> <button aria-label="copy" title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre>[&lt;tf.Variable 'simple_model/output/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)&gt;,
 &lt;tf.Variable 'simple_model/output/weights:0' shape=(16384, 1) dtype=float32, numpy=
 array([[ 0.03065354],
        [ 0.0149726 ],
        [-0.02742667],
        ...,
        [-0.01549608],
        [ 0.01788269],
        [ 0.05695942]], dtype=float32)&gt;]
</pre></table></code></div></div><p>We finally have a model!.</p><h2 id="further-steps">Further steps</h2><p>Once the final model is designed we can create a custom training pipeline. This involves using a training loop as in PyTorch where we need to define training and validation steps.</p><p>To write a custom training step we can use <code class="language-plaintext highlighter-rouge">tf.GradientTape</code> and decorate its function with <code class="language-plaintext highlighter-rouge">@tf.function</code> to speed up its computation. This tutorial in the official <a href="https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch">Tensorflow documentation</a> shows pretty well how the low level training/validation loop logic works. The main difference in this case would be using the model we defined above instead of <code class="language-plaintext highlighter-rouge">tf.keras.Model</code>.</p><p>Additional steps might imply writing a summary to log the training metrics in Tensorboard (using <code class="language-plaintext highlighter-rouge">tf.summary.create_file_writer</code>) and save checkpoints with the help of a checkpoint manager (<code class="language-plaintext highlighter-rouge">tf.train.Checkpoint</code> and <code class="language-plaintext highlighter-rouge">tf.train.CheckpointManager</code>). I will create another blog post showing their usage when writing low level TF pipelines.</p><p>For now, this link serves as a example showing how to manage these custom training pipeline concepts (summaries and checkpoints) in some models written with <code class="language-plaintext highlighter-rouge">tf.keras.Model</code> for retina damage detection in OCT scans: <a href="https://github.com/miguelalba96/OCT_project">Link</a></p><p>This is a link to the Google Colab to run all the code from this post: <a href="https://colab.research.google.com/drive/18KOzhewyqBGAw_zNWfKWW1IA85qecn1c?usp=sharing">Link</a></p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/machine-learning/'>Machine Learning</a>, <a href='/categories/tensorflow/'>Tensorflow</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/deep-neural-networks/" class="post-tag no-text-decoration" >Deep neural networks</a> <a href="/tags/tensorflow/" class="post-tag no-text-decoration" >Tensorflow</a> <a href="/tags/python/" class="post-tag no-text-decoration" >Python</a> <a href="/tags/machine-learning/" class="post-tag no-text-decoration" >Machine learning</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=How to build deep neural networks using Tensorflow low level API (tf.Module) - Miguel Alba&url=https://miguelalba96.github.io/posts/Tensorflow-low-level-API/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=How to build deep neural networks using Tensorflow low level API (tf.Module) - Miguel Alba&u=https://miguelalba96.github.io/posts/Tensorflow-low-level-API/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://www.linkedin.com/sharing/share-offsite/?url=https://miguelalba96.github.io/posts/Tensorflow-low-level-API/" data-toggle="tooltip" data-placement="top" title="Linkedin" target="_blank" rel="noopener" aria-label="Linkedin"> <i class="fa-fw fab fa-linkedin"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/Welcome/">Welcome!</a><li><a href="/posts/Tensorflow-low-level-API/">How to build deep neural networks using Tensorflow low level API (tf.Module)</a><li><a href="/posts/FisherInformation-DL/">The relevance of the Fisher Information Matrix in Deep Neural Networks</a><li><a href="/posts/LinearModels-intro/">Linear models 101! - Introduction</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/deep-neural-networks/">Deep neural networks</a> <a class="post-tag" href="/tags/machine-learning/">Machine learning</a> <a class="post-tag" href="/tags/continual-learning/">Continual learning</a> <a class="post-tag" href="/tags/fisher-information-matrix/">Fisher Information Matrix</a> <a class="post-tag" href="/tags/inference/">Inference</a> <a class="post-tag" href="/tags/linear-models/">Linear Models</a> <a class="post-tag" href="/tags/python/">Python</a> <a class="post-tag" href="/tags/statistics/">Statistics</a> <a class="post-tag" href="/tags/tensorflow/">Tensorflow</a> <a class="post-tag" href="/tags/welcome/">Welcome</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/LinearModels-intro/"><div class="card-body"> <span class="timeago small" >Oct 14, 2021<i class="unloaded">2021-10-14T01:00:00+02:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Linear models 101! - Introduction</h3><div class="text-muted small"><p> Simple Linear Regression We can express the behavior of several things around nature based on their relationships. There are several types of relationships between things, some of them could descr...</p></div></div></a></div><div class="card"> <a href="/posts/FisherInformation-DL/"><div class="card-body"> <span class="timeago small" >Jan 22<i class="unloaded">2022-01-22T19:00:00+01:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>The relevance of the Fisher Information Matrix in Deep Neural Networks</h3><div class="text-muted small"><p> Introduction Deep models have always been considered as black boxes, where provided that sufficient and clean data and a clear problem statement are available, they can produce models with reliabl...</p></div></div></a></div><div class="card"> <a href="/posts/Welcome/"><div class="card-body"> <span class="timeago small" >Oct 13, 2021<i class="unloaded">2021-10-13T01:00:00+02:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Welcome!</h3><div class="text-muted small"><p> Hi, I am Miguel, this is my website and research blog. If you are interested in my profile you can find here information about my educational background and experience. If you are interested in wo...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/LinearModels-intro/" class="btn btn-outline-primary" prompt="Older"><p>Linear models 101! - Introduction</p></a> <a href="/posts/FisherInformation-DL/" class="btn btn-outline-primary" prompt="Newer"><p>The relevance of the Fisher Information Matrix in Deep Neural Networks</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2022 <a href="https://github.com/miguelalba96">Miguel Alba</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/deep-neural-networks/">Deep neural networks</a> <a class="post-tag" href="/tags/machine-learning/">Machine learning</a> <a class="post-tag" href="/tags/continual-learning/">Continual learning</a> <a class="post-tag" href="/tags/fisher-information-matrix/">Fisher Information Matrix</a> <a class="post-tag" href="/tags/inference/">Inference</a> <a class="post-tag" href="/tags/linear-models/">Linear Models</a> <a class="post-tag" href="/tags/python/">Python</a> <a class="post-tag" href="/tags/statistics/">Statistics</a> <a class="post-tag" href="/tags/tensorflow/">Tensorflow</a> <a class="post-tag" href="/tags/welcome/">Welcome</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://miguelalba96.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script>
